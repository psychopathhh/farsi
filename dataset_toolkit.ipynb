{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12febf25",
   "metadata": {},
   "source": [
    "## Dataset generator\n",
    "This notebook is configured to work with armenian language\n",
    "\n",
    "You should start by seeing `preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a7465",
   "metadata": {},
   "source": [
    "\n",
    "### Main code\n",
    "First cell of this notebook is just defining functions and importing dependencies, and as such can be used as a standalone module for your adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051af927-e40e-4c12-8f4c-b4f335ba937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mGetting data..\u001b[0m\n",
      "\u001b[34;1m\t-> done\u001b[0m\n",
      "'results/' already exists\n",
      "\u001b[32;1mStoring the output in: results/SynthText.h5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "the STRING opcode argument must be quoted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    147\u001b[39m mode = \u001b[33m'\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m'\u001b[39m           \u001b[38;5;66;03m# Режим выбора: 'r' или 'o'\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Запуск генерации\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances_per_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(db, num_img, instances_per_img, mode)\u001b[39m\n\u001b[32m     98\u001b[39m random.shuffle(random_indexes)\n\u001b[32m     99\u001b[39m iterator = tqdm(\n\u001b[32m    100\u001b[39m   random_indexes[:num_img] \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_img),\n\u001b[32m    101\u001b[39m   desc=\u001b[33m\"\u001b[39m\u001b[33mGoing through images...\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m   total=num_img\n\u001b[32m    103\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m RV3 = \u001b[43mRendererV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSECS_PER_IMG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[32m    107\u001b[39m   imname = imnames[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\printed_text_ocr_generator_fa\\SynthTextCore\\synthgen.py:369\u001b[39m, in \u001b[36mRendererV3.__init__\u001b[39m\u001b[34m(self, data_dir, max_time)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dir, max_time=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28mself\u001b[39m.text_renderer = \u001b[43mtu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRenderFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m.colorizer = Colorize(data_dir)\n\u001b[32m    371\u001b[39m     \u001b[38;5;66;03m#self.colorizerV2 = colorV2.Colorize(data_dir)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\printed_text_ocr_generator_fa\\SynthTextCore\\text_utils.py:109\u001b[39m, in \u001b[36mRenderFont.__init__\u001b[39m\u001b[34m(self, data_dir)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m.text_source = TextSource(min_nchar=\u001b[38;5;28mself\u001b[39m.min_nchar,\n\u001b[32m    106\u001b[39m                               fn=osp.join(data_dir,\u001b[33m'\u001b[39m\u001b[33mnewsgroup/newsgroup.txt\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# get font-state object:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28mself\u001b[39m.font_state = \u001b[43mFontState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m pygame.init()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Documents\\GitHub\\printed_text_ocr_generator_fa\\SynthTextCore\\text_utils.py:425\u001b[39m, in \u001b[36mFontState.__init__\u001b[39m\u001b[34m(self, data_dir)\u001b[39m\n\u001b[32m    423\u001b[39m     u = pickle._Unpickler(f)\n\u001b[32m    424\u001b[39m     u.encoding = \u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     p = \u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.char_freq = p\n\u001b[32m    428\u001b[39m \u001b[38;5;66;03m# get the model to convert from pixel to font pt size:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pickle.py:1380\u001b[39m, in \u001b[36m_Unpickler.load_string\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1378\u001b[39m     data = data[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m]\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mthe STRING opcode argument must be quoted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1381\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28mself\u001b[39m._decode_string(codecs.escape_decode(data)[\u001b[32m0\u001b[39m]))\n",
      "\u001b[31mUnpicklingError\u001b[39m: the STRING opcode argument must be quoted"
     ]
    }
   ],
   "source": [
    "# Author: Ankush Gupta\n",
    "# Date: 2015\n",
    "\n",
    "# Date of rework for armenian language support: 2024\n",
    "# Author: Abilov Damir\n",
    "\n",
    "\"\"\"\n",
    "Entry-point for generating synthetic text images, as described in:\n",
    "\n",
    "@InProceedings{Gupta16,\n",
    "      author       = \"Gupta, A. and Vedaldi, A. and Zisserman, A.\",\n",
    "      title        = \"Synthetic Data for Text Localisation in Natural Images\",\n",
    "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
    "      year         = \"2016\",\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os, sys, traceback\n",
    "import os.path as osp\n",
    "from SynthTextCore.synthgen import *\n",
    "from SynthTextCore.common import *\n",
    "import wget, tarfile\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "## Define some configuration variables:\n",
    "SECS_PER_IMG = 2 #max time per image in seconds\n",
    "\n",
    "# path to the data-file, containing image, depth and segmentation:\n",
    "DATA_PATH = 'data'\n",
    "DB_FNAME = osp.join(DATA_PATH,'dset.h5')\n",
    "# url of the data (google-drive public file):\n",
    "DATA_URL = 'http://www.robots.ox.ac.uk/~ankush/data.tar.gz'\n",
    "OUT_FILE = 'results/SynthText.h5'\n",
    "\n",
    "# Disabled automatic download of useless models - should just instruct user to see preprocessing.ipynb \n",
    "def get_data():\n",
    "  # \"\"\"\n",
    "  # Download the image,depth and segmentation data:\n",
    "  # Returns the h5 database.\n",
    "  # \"\"\"\n",
    "  # if not osp.exists(DB_FNAME):\n",
    "  #   try:\n",
    "  #     colorprint(Color.BLUE,'\\tdownloading data (56 M) from: '+DATA_URL,bold=True)\n",
    "  #     print()\n",
    "  #     sys.stdout.flush()\n",
    "  #     out_fname = 'data.tar.gz'\n",
    "  #     wget.download(DATA_URL,out=out_fname)\n",
    "  #     tar = tarfile.open(out_fname)\n",
    "  #     tar.extractall()\n",
    "  #     tar.close()\n",
    "  #     os.remove(out_fname)\n",
    "  #     colorprint(Color.BLUE,'\\n\\tdata saved at:'+DB_FNAME,bold=True)\n",
    "  #     sys.stdout.flush()\n",
    "  #   except:\n",
    "  #     print (colorize(Color.RED,'Data not found and have problems downloading.',bold=True))\n",
    "  #     sys.stdout.flush()\n",
    "  #     sys.exit(-1)\n",
    "\n",
    "  if not osp.exists(DB_FNAME):\n",
    "    print(DB_FNAME, \"doesn't exist, you likely didn't set up project properly. See preprocessing.ipynb for instructions.\")\n",
    "  # open the h5 file and return:\n",
    "  return h5py.File(DB_FNAME,'r')\n",
    "\n",
    "\n",
    "def add_res_to_db(imgname,res,db):\n",
    "  \"\"\"\n",
    "  Add the synthetically generated text image instance\n",
    "  and other metadata to the dataset.\n",
    "  \"\"\"\n",
    "  ninstance = len(res)\n",
    "  for i in range(ninstance):\n",
    "    dname = \"%s_%d\"%(imgname, i)\n",
    "    db['data'].create_dataset(dname,data=res[i]['img'])\n",
    "    db['data'][dname].attrs['charBB'] = res[i]['charBB']\n",
    "    db['data'][dname].attrs['wordBB'] = res[i]['wordBB']        \n",
    "    #db['data'][dname].attrs['txt'] = res[i]['txt']\n",
    "    L = res[i]['txt']\n",
    "    L = [n.encode(\"utf-8\") for n in L]\n",
    "    db['data'][dname].attrs['txt'] = L\n",
    "\n",
    "def main(db, num_img, instances_per_img, mode):\n",
    "  # open the output h5 file:\n",
    "  try:\n",
    "    os.mkdir(\"results/\")\n",
    "  except OSError:\n",
    "    print(\"'results/' already exists\")\n",
    "  out_db = h5py.File(OUT_FILE,'w')\n",
    "  try:\n",
    "    out_db.create_group('/data')\n",
    "    print (colorize(Color.GREEN,'Storing the output in: '+OUT_FILE, bold=True))\n",
    "    \n",
    "    imnames = list(db['image'].keys())\n",
    "    # If mode == 'random', uses num_img random indexies\n",
    "    random_indexes = list(range(len(imnames)))\n",
    "    random.shuffle(random_indexes)\n",
    "    iterator = tqdm(\n",
    "      random_indexes[:num_img] if mode == 'random' else range(num_img),\n",
    "      desc=\"Going through images...\",\n",
    "      total=num_img\n",
    "    )\n",
    "\n",
    "    RV3 = RendererV3(DATA_PATH,max_time=SECS_PER_IMG)\n",
    "    for i in iterator:\n",
    "      imname = imnames[i]\n",
    "      # get the image:\n",
    "      img = Image.fromarray(db['image'][imname][:])\n",
    "      # get the pre-computed depth:\n",
    "      #  there are 2 estimates of depth (represented as 2 \"channels\")\n",
    "      #  here we are using the second one (in some cases it might be\n",
    "      #  useful to use the other one):\n",
    "      depth = db['depth'][imname][:].T\n",
    "      depth = depth[:,:,1]\n",
    "      # get segmentation:\n",
    "      seg = db['seg'][imname][:].astype('float32')\n",
    "      area = db['seg'][imname].attrs['area']\n",
    "      label = db['seg'][imname].attrs['label']\n",
    "\n",
    "      # re-size uniformly:\n",
    "      sz = depth.shape[:2][::-1]\n",
    "      img = np.array(img.resize(sz,Image.Resampling.LANCZOS))\n",
    "      seg = np.array(Image.fromarray(seg).resize(sz,Image.Resampling.NEAREST))\n",
    "\n",
    "      # update the iterator progress bar\n",
    "      iterator.set_description(f\"Generating {instances_per_img} images of {imname}\")\n",
    "      res = RV3.render_text(img,depth,seg,area,label,\n",
    "                            ninstance=instances_per_img,viz=False)\n",
    "      if len(res) > 0:\n",
    "        # non-empty : successful in placing text:\n",
    "        add_res_to_db(imname,res,out_db)\n",
    "      \n",
    "  finally:\n",
    "    db.close()\n",
    "    out_db.close()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Инициализация и получение данных\n",
    "    print(colorize(Color.BLUE, 'Getting data..', bold=True))\n",
    "    db = get_data()\n",
    "    print(colorize(Color.BLUE, '\\t-> done', bold=True))\n",
    "    \n",
    "    # Параметры генерации (можно заменить на ввод от пользователя)\n",
    "    num_img = 5              # Количество обрабатываемых изображений\n",
    "    instances_per_img = 2     # Вариантов текста на каждое изображение\n",
    "    mode = 'random'           # Режим выбора: 'r' или 'o'\n",
    "    \n",
    "    # Запуск генерации\n",
    "    main(db, num_img, instances_per_img, mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eabea1",
   "metadata": {},
   "source": [
    "## Using the generator\n",
    "This cell will:\n",
    "  - download small sample dataset of images, if there is no `data/dset.h5`\n",
    "    - along with that it replaces any files in `data/` with original (english) settings\n",
    "    - if you want to run it with armenian, substitute folders in `data/` with custom ones from `data AM substitution/`\n",
    "    - if there is already `data/dset.h5`, it will be used instead\n",
    "  - ask you how many images from `data/dset.h5` do you want to use\n",
    "  - ask you how many variants do you want generated per image\n",
    "  - ask you how do you want to choose images from `data/dset.h5`\n",
    "    - 'r': random mode, images will be used in random order (without repetitions)\n",
    "    - 'o': ordered mode, images will be used in alphabetical order\n",
    "  - show progress of placing text on images\n",
    "  - save images with text to another dataset `results/SynthText.h5`, now containing:\n",
    "    - images themselves\n",
    "    - text on each individual one\n",
    "    - bounding boxes of words and individual letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2036df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mgetting data..\u001b[0m\n",
      "\u001b[34;1m\t-> done\u001b[0m\n",
      "Images available in `data/dset.h5`: ~5                 \n",
      "How many do you want to use for generation? (-1 = ALL)\n",
      ">>>\n",
      "\n",
      "5 different images will be used.                 \n",
      "How many versions do you want per 1 image?\n",
      ">>>\n",
      "\n",
      "Choose mode: \n",
      "r=random images will be used,            \n",
      "[anything else]=images will be used in alphabetical order\n",
      ">>>\n",
      "'results/' already exists\n",
      "\u001b[32;1mStoring the output in: results/SynthText.h5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 2 images of indian+musicians_116.jpg: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print (colorize(Color.BLUE,'getting data..',bold=True))\n",
    "    db = get_data()\n",
    "    print (colorize(Color.BLUE,'\\t-> done',bold=True))\n",
    "    N = len(db['image'].keys())\n",
    "\n",
    "    print(f\"Images available in `data/dset.h5`: ~{N} \\\n",
    "                \\nHow many do you want to use for generation? (-1 = ALL)\\n>>>\")\n",
    "    num_img = int(input())\n",
    "    num_img = N if num_img < 0 else min(max(1,num_img), N)\n",
    "\n",
    "    print(f\"\\n{num_img} different images will be used. \\\n",
    "                \\nHow many versions do you want per 1 image?\\n>>>\")\n",
    "    instances_per_img = int(input())\n",
    "    instances_per_img = max(1, instances_per_img)\n",
    "\n",
    "\n",
    "    print(\"\\nChoose mode: \\nr=random images will be used, \\\n",
    "           \\n[anything else]=images will be used in alphabetical order\\n>>>\")\n",
    "    if 'r' == input().lower():\n",
    "        mode = 'random'\n",
    "    else:\n",
    "        mode = 'order'\n",
    "\n",
    "    main(db, num_img, instances_per_img, mode)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d0e73",
   "metadata": {},
   "source": [
    "## Visualizing generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804ea6b",
   "metadata": {},
   "source": [
    "This notebook takes generated images from `results/SynthText.h5` and displays them with various settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f44fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import h5py \n",
    "from SynthTextCore.common import *\n",
    "\n",
    "\n",
    "def viz_textbb(text_im, charBB_list, wordBB, alpha=1.0):\n",
    "    \"\"\"\n",
    "    text_im : image containing text\n",
    "    charBB_list : list of 2x4xn_i bounding-box matrices\n",
    "    wordBB : 2x4xm matrix of word coordinates\n",
    "    \"\"\"\n",
    "    plt.close(1)\n",
    "    plt.figure(1)\n",
    "    plt.imshow(text_im)\n",
    "    H,W = text_im.shape[:2]\n",
    "\n",
    "    # plot the character-BB:\n",
    "    if charBB_list is not None:\n",
    "        for i in range(len(charBB_list)):\n",
    "            bbs = charBB_list[i]\n",
    "            ni = bbs.shape[-1]\n",
    "            for j in range(ni):\n",
    "                bb = bbs[:,:,j]\n",
    "                bb = np.c_[bb,bb[:,0]]\n",
    "                plt.plot(bb[0,:], bb[1,:], 'r', alpha=alpha/2)\n",
    "\n",
    "    # plot the word-BB:\n",
    "    if wordBB is not None:\n",
    "        for i in range(wordBB.shape[-1]):\n",
    "            bb = wordBB[:,:,i]\n",
    "            bb = np.c_[bb,bb[:,0]]\n",
    "            plt.plot(bb[0,:], bb[1,:], 'g', alpha=alpha)\n",
    "            \n",
    "            # remove comment to visualize the individual vertices:\n",
    "            # vcol = ['r','g','b','k']\n",
    "            # for j in range(4):\n",
    "            #     plt.scatter(bb[0,j],bb[1,j],color=vcol[j])        \n",
    "\n",
    "    plt.gca().set_xlim([0,W-1])\n",
    "    plt.gca().set_ylim([H-1,0])\n",
    "    plt.show(block=True)\n",
    "\n",
    "def main(db, num_images, no_delay_render, render_word_BBs, render_char_BBs):\n",
    "    dsets = sorted(db['data'].keys())\n",
    "    for k in dsets:\n",
    "        rgb = db['data'][k][...]\n",
    "        charBB = db['data'][k].attrs['charBB']\n",
    "        wordBB = db['data'][k].attrs['wordBB']\n",
    "        txt = db['data'][k].attrs['txt']\n",
    "\n",
    "        print (\"image name        : \", colorize(Color.BLUE, k, bold=True))\n",
    "        print (\"  ** no. of chars : \", colorize(Color.YELLOW, charBB.shape[-1]))\n",
    "        print (\"  ** no. of words : \", colorize(Color.YELLOW, wordBB.shape[-1]))\n",
    "        print (\"  ** text         : \", [word for word in txt])\n",
    "        viz_textbb(\n",
    "            rgb, \n",
    "            [charBB] if render_char_BBs else None, \n",
    "            wordBB if render_word_BBs else None\n",
    "        )\n",
    "        num_images -= 1\n",
    "        if num_images == 0:\n",
    "            break\n",
    "        if no_delay_render:\n",
    "            continue\n",
    "        if 'q' in input(\"next? ('q' to exit) : \"):\n",
    "            break\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccd82b",
   "metadata": {},
   "source": [
    "### Entry point\n",
    "Run the notebook from here.\n",
    "You have the options for rendering all at once or one by one; rendering bounding boxes of words and letters or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ffa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    db = h5py.File('results/SynthText.h5', 'r')\n",
    "    N = len(db['data'].keys())\n",
    "    print (\"total number of images : \", colorize(Color.RED, N, bold=True))\n",
    "    \n",
    "    print(\"How many of them do you want to see?\\n>>>\")\n",
    "    num_images = min(max(1, int(input())), N) \n",
    "\n",
    "    print(\"Slow down?\\nn: will render all the images at once [Caution! It's not a good idea for large amount of images] \\\n",
    "      \\n[anything else]: will wait for user input before rendering the next image\\n>>>\")\n",
    "    no_delay_render = True if input().lower() == 'n' else False\n",
    "\n",
    "    print(\"\\nRender word bounding boxes?\\ny: will render word BBs \\\n",
    "      \\n[anything else]: won't render word BBs\\n>>>\")\n",
    "    render_word_BBs = True if input().lower() == 'y' else False\n",
    "\n",
    "    print(\"\\nRender character bounding boxes?\\ny: will render character BBs \\\n",
    "      \\n[anything else]: won't render character BBs\\n>>>\")\n",
    "    render_char_BBs = True if input().lower() == 'y' else False\n",
    "\n",
    "    main(db, num_images, no_delay_render, render_word_BBs, render_char_BBs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
